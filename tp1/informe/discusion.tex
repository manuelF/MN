\section{Discusi\'on}

En un primer momento, el \'enfasis estuvo puesto en hacer funcionar el m\'etodo 
de Newton.
Este m\'etodo fue el primero en ser planteado e implementado debido a la
importancia recibida tanto en clase como en el material de lectura consultado.
Consecuentemente con lo esperado el m\'etodo de Newton funcion\'o exitosamente
sin la necesidad de mayores incursiones en el c\'odigo original o en las cuentas
realizadas previamente.

Luego, investigando por los otros m\'etodos de c\'alculo de ra\'ices; 
el primero que se present\'o fue la aproximaci\'on num\'erica de Newton, 
el m\'etodo de la secante. Las complejidades encontradas para el desarrollo de 
esta funci\'on fueron la facilidad con la cual el denominador tiende a cero, 
convirtiendo la cuenta en NaN (Not a Number) rapidamente. Elegimos para 
reemplazarlo el m\'etodo de Regula Falsi.

Un detalle interesante es que entre m\'as decimales se emplean, m\'as rapido 
converge el m\'etodo de Newton. Esto tiene sentido debido a que las 
aproximaciones num\'ericas son cada vez mejores. Tambi\'en se observa que para 
valores de precision muy bajos (menos de 14 decimales binarios en promedio), 
Newton directamente diverge. 
Este fenomeno se debe a que la precisi\'on del epsilon elegido 
($\epsilon = 10^{-4}$) es apenas mayor que $2^{-14}$. 
Esto produce que queden pocos bits para la que ser\'ia parte entera dentro de 
la mantisa. Como esos bits se tienen que compartir entre parte entera y parte 
decimal, no se tienen exactamente 14 bits para los decimales, sino que a medida 
que se va a agrandando el n\'umero, la densidad de los reales representables 
disminuye dr\'asticamente.

Fue de inter\'es trazar las curvas de aproximaci\'on de las variables. 
Esto es de alta relevancia ya que se puede ver realmente el impacto que se tiene
al utilizar mayor cantidad de d\'igitos. Lo m\'as notable fue visuzalizar la 
aproximaci\'on asint\'otica a los valores ``verdaderos'' de las variables, 
y como las ganancias marginales a partir de, en promedio, 22 decimales, 
se vuelven despreciables. Nuestra hip\'otesis es que con esa cantidad de 
d\'igitos, la mantisa puede ser suficientemente bien ajustada a tal punto que puede 
ser representada bien la parte entera y la parte decimal minimice los errores de 
operaci\'on. Por ejemplo, en el caso 1, como $\beta = 9$, se necesitan al menos 
5 bits para representar la parte entera. Luego, todos los restantes seran usados 
para decimales. Si hubiera 15 bits en total, quedar\'ian 10 bits para la parte 
decimal. $2^{-10}<10{-4}<2^{-9}$, luego la parte decimal, va a tener una
precisi\'on cercana a $\frac{1}{1000}$, en caso promedio. 
Sin embargo no alcanza a converger a los valores originales que generaron los 
datos por la acumulacion de errores en, por ejemplo, las funciones
de sumatoria, logaritmos y potenciaci\'on. Esta \'ultima es especialmente 
sensible a los errores en el exponente, y cuando se la procesa de forma 
acumulada (como en una sumatoria), se puede llegar a arrastrar un error
considerable. Como la funci\'on que estima
$\beta$ utiliza sucesivas sumatorias y potencia, podemos ver que ese es un punto 
importante a la hora de intentar minimizar el error de la estimaci\'on.

Debido a discrepancias de convergencia en los casos 1 y 2 utilizando el m\'etodo
de Regla falsa, se procedi\'o a buscar una mejora en este que nos permita una mejor
tasa de convergencia y un ajuste en los valores. Esto fue logrado mediante la
implementaci\'on del algoritmo de Illinois. Gracias a esta mejora se alcanzaron 
mejores curvas de valores.

Como podemos ver en las figuras 2 y 3, la aproximaci\'on que obtenemos de $\beta$ se ajusta bastante
a los datos a\'un con poca precisi\'on cuando utilizamos el m\'etodo de Newton. En la figura 4 podemos
observar que a partir de 22 bits de precisi\'on el valor de $\beta$ se acerca lo suficiente al valor
al cual converge.

En las figuras 5 y 6 observamos que, utilizando el m\'etodo de Regula Falsi (en su versi\'on Illinois)
con 15 bits de precisi\'on el valor de $\beta$ no es lo suficientemente adecuado como para que la curva
se ajuste a los datos. A partir de 17 bits de precisi\'on, en cambio, ya empieza a acercarse m\'as curva
a lo que vale realmente de acuerdo a lo que podemos observar comparandola con los datos de entrada.

En la figura 7 observamos que a partir de 22 d\'igitos de precisi\'on binaria el valor de $\beta$ empieza
a acercarse al valor al cual converge, al igual que con el m\'etodo de Newton.

En la figura 8 graficamos la cantidad de iteraciones y el valor de $\beta$ en funci\'on del valor de $\epsilon$
que utilizamos. Podemos observar que, con 21 bits de presici\'on, a partir de un $\epsilon$ de $10^{-5}$ el m\'etodo
empieza a cortar por cantidad de iteraciones y $\beta$ empieza a converger correctamente.

Con 50 bits de precisi\'on, en cambio, $\beta$ converge a partir de un $\epsilon$ de $10^{-3}$ y corta siempre por 
el $\epsilon$ en lugar de por cantidad de iteraciones. Esto se debe a que al haber m\'as precisi\'on el m\'etodo converge m\'as
r\'apido y a un valor m\'as exacto.

Con Regula Falsi podemos observar un comportamiento similar en lo que respecta a cantidad de iteraciones, aunque para asegurar
la convergencia debemos tener un valor de $\epsilon$ m\'as chico. Esto se debe a que el m\'etodo no es tan eficiente como el
m\'etodo de Newton.