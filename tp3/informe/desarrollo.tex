\section{Desarrollo}

\subsection{Herramientas}

Para la realizaci\'on de los experimentos se utilizaron C++ y matlab como lenguajes de
programaci\'on para los algoritmos principales. Durante la realizaci\'on de este trabajo nos encontramos con
la primera barrera en tiempo de corrida de un programa. A la hora de generar la matriz de covarianza tarda
aproximadamente 5 horas en generarse debido al gran tama\~no de la matriz de entrada.

El an\'alisis de los resultados y el ploteo de los gr\'aficos se realiz\'o
mediante el uso del entorno \href{http://www.matlab.com/}{MATLAB}

El control de los experimentos y las ``recetas'' de las experiencias se ven
reflejadas en scripts de shell que levantan archivos de datos con tests
preprogramdos, ejecutan los algoritmos y luego analizan los resultados,
resumiendolos en output en forma de informaci\'on tabular y gr\'aficos.
La existencia de un Makefile fue clave a la hora de automatizar tareas de
compilaci\'on y corrida de tests, para poder ser lo mas automatizados dentro de
lo posible.

Se utiliz\'o \href{http://www.latex-project.org/}{\LaTeX} para la escritura y el formato del informe,
manteniendo la estructura de informe del Trabajo Pr\'actico N\'umero 1 y 2 y tambi\'en
permitiendo expresar estructuras y f\'ormulas matem\'aticas de una manera simple y clara.

\subsection{Manejo de la complejidad del experimento}

La dificultad del desarrollo de este experimento fue un poco m\'as elevada a la de los dos
trabajos pr\'acticos anteriores.
En primer lugar, se decidi\'o hacer primero todo el trabajo pr\'actico en Matlab para obtener
una pronta aproximaci\'on a los resultados, siendo el desarrollo ampliamente m\'as comodo que
en C++ (dado que la SVD forma parte de la libreria estandar de Matlab). Una vez implementado
el TP en Matlab, se procedi\'p a realizar el experimento en C++. El primer problema encontrado
a la hora de implementar el experimento en Matlab fue que al calcular la SVD con 60.000 imagenes,
se generaba una matriz de $60.000 \times 60.000$ elementos de tipo double, que no entraba en
memoria, es por eso que se decidi\'o utilizar s\'olo 40.000 imagenes para el experimento en Matlab.

Luego de desarrollar y contar con el experimento funcionando en Matlab, se empez\'o la programaci\'on
del mismo en C++. La primera variaci\'on significativa en la implementaci\'on se refiere al
descubrimiento de que no es necesario calcular la SVD, sino s\'olo la matriz $V$, resultando
en el c\'alculo de una matriz de $60.000 \times 784$ en vez de una de $60.000 \times 60.000$.
A\'un as\'i, consideraciones posteriores sugirieron que 60.000 im\'agenes era un n\'umero por
dem\'as excesivo y por lo tanto el experimento pas\'o operar con s\'olo 30.000 imagenes.
Al analizar los resultados se corrobor\'o que 30.000 im\'agenes conforman una muestra significativa,
y por lo tanto se realiz\'o el trabajo pr\'actico usando 30.000 imagenes de entrenamiento y 500 imagenes de test.

\subsection{Matriz de Covarianza}

El primer paso consisti\'o en generar la matriz de covarianza con las 30.000 imagenes tomadas como datos
de entrenamiento. Para eso se utiliz\'o la f\'ormula del enunciado.

Se gener\'o la matriz $X$ a trav\'es
de la sustracci\'on a cada entrada de la matriz del promedio del pixel que
representa (promedio de ese pixel en todas las imagenes) y la posterior
divisi\'on la matriz por $\sqrt{n-1}$ seg\'un reza la siguiente formula:

$(x_i - \mu)^{t}/\sqrt{n-1}$, y $$X=U \Sigma V^t$$

Para calcular la matriz de covarianza, a la que llamamos $Mx$, se realiz\'o el
producto $X^tX$. Este paso es el acercamiento necesario para realizar el cambio
de base computado para la disminuci\'on en la redundancia de los datos buscada.

El primer paso consisti\'o en generar la matriz de covarianza con las 30.000 imagenes tomadas como datos
de entrenamiento. Para eso se utiliz\'o la f\'ormula del enunciado. Se gener\'o la matriz $X$ a trav\'es
de la sustracci\'on a cada entrada de la matriz del promedio del pixel que representa (promedio de ese
pixel en todas las imagenes) y la posterior divisi\'on la matriz por $\sqrt{n-1}$. Para calcular la
matriz de covarianza, a la que llamamos $Mx$, se realiz\'o el producto $X^tX$.

\subsection{Factorizaci\'on QR}
A la hora de calcular la SVD se present\'o la idea de que s\'olo es necesaria la matriz $V$, es por
eso que en vez de calcular la SVD, se procedi\'o a calcular la matriz $V$ utilizando la factorizaci\'on
QR de la matriz de covarianza. El m\'etodo utilizado para calcular la matriz $V^t$ fue la factorizaci\'on
QR de $Mx$ (la matriz de covarianza) mediante la aplicaci\'on de transformaciones de Householder, y la
posterior multiplicaci\'on RQ (es decir, en el orden inverso), hasta que la suma de los elementos debajo
de la diagonal principal suman menos de 15. La elecci\'on del 15 no fue caprichosa, sino que es el
resultado de la corrida del experimento con $10^{-5}$ en lugar de 15, donde converg\'ia a un n\'umero
entre 14 y 15 por temas de precisi\'on.

Para calcular la matriz $V^t$, se utiliz\'o la factorizaci\'on de Householder y la se implement\'o en $O(n^3)$
siendo $n = 784$. Como el programa resultante tard\'o m\'as de 15 horas en calcular la matriz $V$ usando 30.000 muestras,
se gener\'o el archivo V.txt con esta informaci\'on precalculada, si el archivo no exist\'ia previamente
entonces se genera la matriz y luego se guarda en el archivo, caso contrario, se realiza la lectura del archivo.

Este procedimiento que involucra la generaci\'on de una matriz est\'atica tiene tiene sentido en un contexto
donde los datos de entrenamiento no cambian. Otros experimentos donde nuevo input puede ser fuente de mejoras
en el m\'etodo podr\'ian tener problemas pero por las condiciones presentadas no es el caso.

El algoritmo que utilizamos para la factorizaci\'on $QR$ tiene complejidad $o(n^3)$ ya que para obtener $Q$ hacemos la cuenta
$$Q = I - 2vv^t$$

Y como $R = Q^{-1}A$ y $Q^{-1} = Q^t$ entonces para obtener el producto de las $Q$ calculabamos
$$Q_i = Q_{i-1} - (2v)(v^t Q_{i-1})$$
Y esto sale en $o(n^2)$ con esa agrupaci\'on en par\'entesis y para obtener $R$ hacemos lo mismo con las transpuestas de las $Q$

\subsection{C\'alculo de la Transformaci\'on Caracter\'istica}

Para calcular la transformaci\'on caracter\'istica multiplicamos los $k$ 
autovectores cuyos autovalores asociados eran los de valor m\'as significativo 
por la imagen de la cual queremos obtener qu\'e d\'igito representa.

En este punto finaliza la etapa de entrenamiento del sistema. El cambio de base
fue realizado acarreando la disminuci\'on significativa de informaci\'on
redundante. 

\subsection{Reconocimiento de d\'igitos}
Para reconocer los d\'igitos utilizamos dos algoritmos. El primero de ellos fue tomar distancia (con norma 1, 2 e $\infty$) a
todos los d\'igitos de entrenamiento, y luego comparar con los 100 m\'as cercanos. El m\'as repetido fue finalmente
el elegido para identificar dicha imagen. El otro m\'etodo que utilizamos fue tomar el promedio de las transformaciones
de todos los ceros, de todos los unos, y as\'i con cada d\'igito, y tomar distancia (con las mismas normas)
a cada promedio, quedandonos con la menor distancia.
